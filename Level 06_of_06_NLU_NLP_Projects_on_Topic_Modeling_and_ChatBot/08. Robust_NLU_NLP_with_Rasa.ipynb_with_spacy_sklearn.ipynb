{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EU9saTFpu2Mb"
   },
   "source": [
    "# Robust NLU/NLP with Rasa\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQ1MiOLqu2Me"
   },
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8w3H0EBu2Mg"
   },
   "source": [
    "## 1.1 Method 1: Create Virtual Enviornment(Recommended)\n",
    "- Windows OS need to install VC++ build tools https://aka.ms/vs/16/release/VC_redist.arm64.exe\n",
    "\n",
    "- FYI... http://rasa.com/docs/rasa/user-guide/installation/\n",
    "\n",
    "\n",
    "- Start | All Programs | Anaconda3 | Anaconda Navigator\n",
    "- Click on `Environments` | Click on `Create` | Provide Name as `AICHATBOT` | Select Python version as `3.6` | Click on `Create`\n",
    "- install `jupyter` package from anaconda naviagtor\n",
    "- open `anaconda prompt` as **Administrator**\n",
    "- `pip install spacy`\n",
    "- `pip install rasa`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RbIee7fFu2Mj"
   },
   "source": [
    "### 1.2 Method 2: use base enviornment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcaWE7x2u2Mk"
   },
   "source": [
    "- Rasa NLU Installations\n",
    "- Open anaconda prompt as administrator\n",
    "- run below commands\n",
    "    - <code> conda install python=3.6</code>\n",
    "    - <code> pip install rasa_core</code>\n",
    "    - <code> conda install -c derickl sklearn-crfsuite </code>\n",
    "    - <code> python -m spacy download en </code>\n",
    "    - <code> python -m spacy download en_core_web_sm </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MmC5zlhu2Mm"
   },
   "source": [
    "# 2. RASA NLU\n",
    "- Language Understanding for chatbots and AI assistants\n",
    "- Library for intent recognition & entity extraction\n",
    "- Based on spaCy, scikit-learn,tensorflow & other libraries\n",
    "- [Refer the official Document](https://rasa.com/docs/nlu/)\n",
    "### Understand dialog flow Alarm app/your business of intrest app \n",
    "- open https://dialogflow.com/\n",
    "- signin using your gmail id\n",
    "- Click on **Go to Console**\n",
    "- create new agent with the name of **alarm_test**\n",
    "- Click on **prebuilt agents**\n",
    "- click on **import**\n",
    "- Prepare a excel with Intent/Training Example/Entities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tk7h8VSbu2Mn"
   },
   "source": [
    "## 3. Explore below sites\n",
    "- [Google Product dialogflow](https://dialogflow.com/)\n",
    "- [Microsoft Product Luis](https://www.luis.ai/)\n",
    "- [Facebook Product wit](https://wit.ai/)\n",
    "- To Migrate Product from above products to rasa [explore](https://nlu.rasa.com/migrating.html#section-migration)\n",
    "- To prepare Intents,Training Examples and Enities use [Rasa nlu trainer](https://rasahq.github.io/rasa-nlu-trainer/)\n",
    "- Note: If you need parse json use [Online link](http://json.parser.online.fr/) or notepad++\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pmv6QU7-u2Mq"
   },
   "source": [
    "## 4. Exercise 1:Rasa NLU \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rtWYZJ75u2NE"
   },
   "source": [
    "- In this exercise you'll use Rasa NLU to create an [interpreter](https://en.wikipedia.org/wiki/Interpreter_(computing)), which parses incoming user messages and returns a set of entities. \n",
    "- Your job is to train an interpreter using the `spacy/tensorflow` entity recognition model in rasa NLU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jL9mHrgru2NF"
   },
   "source": [
    "#### Step 1: Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tdEQ18FWu2NG"
   },
   "outputs": [],
   "source": [
    "from rasa.nlu.training_data import load_data\n",
    "from rasa.nlu.config import RasaNLUModelConfig\n",
    "from rasa.nlu.model import Trainer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wunEx_ZEu2NK"
   },
   "source": [
    "#### Step 2: Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoTJ8VJFu2NL"
   },
   "outputs": [],
   "source": [
    "# Create args dictionary\n",
    "#args = {\"pipeline\": \"spacy_sklearn\"}\n",
    "args = {\"pipeline\": \"pretrained_embeddings_spacy\"}\n",
    "# Create a configuration and trainer\n",
    "config = RasaNLUModelConfig(configuration_values=args)\n",
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlMPdLuau2NQ"
   },
   "source": [
    "#### Step 3: Prepare Intents, Training Examples and Entities\n",
    "- [Open RASA NLU Trainer](https://rasahq.github.io/rasa-nlu-trainer/)\n",
    "- Did you understand how to add Intents / training examples / Entities?\n",
    "- Did you understand sample data? How many Intents are there in sample data?\n",
    "\n",
    "    - <input type=\"radio\" disabled> One\n",
    "    - <input type=\"radio\" disabled> Two\n",
    "    - <input type=\"radio\" disabled> Three\n",
    "    - <input type=\"radio\" disabled checked> Four "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qk0LJRi4u2NR"
   },
   "source": [
    "#### Step 4: Load Training Data\n",
    "- Download Training data from [RASA NLU Trainier](https://rasahq.github.io/rasa-nlu-trainer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGb5u47Bu2NS"
   },
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "training_data = load_data(\"C:\\\\Users\\\\ramreddymyla\\\\Google Drive\\\\01 DS ML DL NLP and AI With Python Lab Copy\\\\02 Lab Data\\\\Python\\\\testData.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rasa.nlu.training_data.training_data.TrainingData at 0x1f07ef1de80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNYzyaalu2NV"
   },
   "source": [
    "#### Step 5: Create Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FekRFnWau2NV",
    "outputId": "4f522d89-d682-4d47-b396-cb3db5eb282e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NB3xXztuu2Nb"
   },
   "source": [
    "#### Step 6: Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yg3TTvAau2Nc",
    "outputId": "204ad0ee-7d9f-4eeb-e485-c057c9b167c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"restaurant_search\",\n",
      "    \"confidence\": 0.7188664513998786\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 18,\n",
      "      \"end\": 25,\n",
      "      \"value\": \"mexican\",\n",
      "      \"entity\": \"cuisine\",\n",
      "      \"confidence\": 0.7098588870914954,\n",
      "      \"extractor\": \"CRFEntityExtractor\"\n",
      "    },\n",
      "    {\n",
      "      \"start\": 44,\n",
      "      \"end\": 49,\n",
      "      \"value\": \"north\",\n",
      "      \"entity\": \"location\",\n",
      "      \"confidence\": 0.8034438501034744,\n",
      "      \"extractor\": \"CRFEntityExtractor\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"restaurant_search\",\n",
      "      \"confidence\": 0.7188664513998786\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.1329389329308321\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.08469317105165598\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.06350144461763338\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"I'm looking for a Mexican restaurant in the North of town\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Try it out\n",
    "import json\n",
    "print(json.dumps(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-w_441Mu2Nf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"greet\",\n",
      "    \"confidence\": 0.7827633235834224\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.7827633235834224\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.11660972121914757\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.06360088339044845\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"restaurant_search\",\n",
      "      \"confidence\": 0.03702607180698126\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"hi\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(json.dumps(interpreter.parse(\"hi\"), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"affirm\",\n",
      "    \"confidence\": 0.886358102828676\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.886358102828676\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.04937941031849713\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.0454882369674241\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"restaurant_search\",\n",
      "      \"confidence\": 0.018774249885402938\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"yes\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(json.dumps(interpreter.parse(\"yes\"), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"goodbye\",\n",
      "    \"confidence\": 0.9345655494592575\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.9345655494592575\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.03832370648145491\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.0236884927964816\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"restaurant_search\",\n",
      "      \"confidence\": 0.003422251262805817\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"bye\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(json.dumps(interpreter.parse(\"bye\"), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "08. Robust_NLU_NLP_with_Rasa.ipynb_with_spacy_sklearn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
