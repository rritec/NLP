{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Word vectors are part of machine learning\n",
    "- Programs which can get better at a task by being exposed to more data\n",
    "- Identifying which intent a user message belongs to\n",
    "- Word vector representation\n",
    "    - Example : “can you help me please”\n",
    "\n",
    "![wv](https://github.com/rritec/datahexa/blob/dev/images/wv.png?raw=true)\n",
    "5.\tWord vectors\n",
    "    - Word vectors try to represent meaning of words\n",
    "    - Words which appear in similar context have similar vectors\n",
    "![wv](https://github.com/rritec/datahexa/blob/dev/images/wv1.png?raw=true) \n",
    "\n",
    "    - Word vectors are computationally intensive\n",
    "    - Training word vectors requires a lot of data\n",
    "    - High quality word vectors are available for anyone to use\n",
    "    - GloVe algorithm\n",
    "        - Cousin of word2vec\n",
    "    - spaCy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exercise 1: Word vectors in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello : [ 4.3282194  -3.6430755  -2.1657367  -1.9960947  -1.5424254  -2.2336278\n",
      " -3.1678445  -1.4595162  -2.6722438   0.88167703  1.4113079  -1.6762991\n",
      "  2.2601454  -4.115002   -4.591881    2.8653836   4.246135   -0.53099513\n",
      "  4.8732014   1.6763593   2.8617158  -2.3739412   0.4426196  -1.9333764\n",
      " -0.1709357   2.411226   -1.3944838   4.969855   -2.6685076   7.369664\n",
      " -1.0670258   1.6429089  -3.7279825   3.1004446  -0.49272776  1.5195935\n",
      "  5.622782    2.5756006   0.9682546  -2.536388   -2.4982843   1.6960979\n",
      "  0.923779   -0.34695888  1.0666676  -2.2407935   1.8322423  -3.4200187\n",
      " -4.4244714  -3.6372359  -3.0243626   2.3175302  -0.6725204  -1.2691791\n",
      " -2.9563584  -1.2566516   4.007683   -0.8363176  -4.152707   -1.2449851\n",
      "  0.541769    1.1443179   3.2188401   0.6067327   0.27883172 -0.3002962\n",
      "  3.478557   -1.6504842   1.7486227   2.6811054  -1.6860063  -0.04018286\n",
      " -4.1077657  -1.209012    0.40722984 -3.9062347   1.404006    1.9799917\n",
      " -0.10898238 -2.7103276  -5.8492513   3.8282547   3.2021286  -0.8585329\n",
      " -3.7872794   1.9038774   2.005034    2.0809634   3.2388332   4.35037\n",
      "  1.3551502   0.31890833 -3.8170862  -2.0319643   0.16600952  4.6285152 ]\n",
      "can : [ 2.9265766e+00  5.8220786e-01  1.1047966e+00 -2.3979316e+00\n",
      " -5.9317589e+00 -4.8414853e-01 -2.2382779e+00  9.8818362e-01\n",
      "  9.7094083e-01 -2.3757963e+00 -3.3996050e+00 -1.8350788e+00\n",
      "  2.6057310e+00  1.0247029e+00  2.8142791e+00  2.5351982e+00\n",
      "  9.5014215e-01 -8.7356639e-01 -7.2686272e+00 -2.2097826e-03\n",
      "  1.1400771e+00 -1.9067883e+00  1.4897401e+00 -2.9471099e-01\n",
      " -3.2145247e+00  6.7464036e-01 -6.3422632e-01 -3.0070033e+00\n",
      " -5.7072563e+00 -3.2993397e-01 -3.8225639e+00 -9.5078981e-01\n",
      " -5.2649908e+00 -6.3428867e-01  1.0691860e-01  1.3924420e-01\n",
      " -3.8609886e+00  6.0487361e+00 -8.6382645e-01 -1.3367879e+00\n",
      "  1.7055048e+00  8.3007193e-01  4.2679772e+00  1.6393936e+00\n",
      " -9.0775716e-01  3.0740211e+00 -2.3192654e+00  4.6879406e+00\n",
      " -1.8248725e+00 -1.9479895e+00  3.1848457e-01 -1.4872780e+00\n",
      "  1.2653786e-01  4.0468493e+00  1.6155953e+00  1.5974107e+00\n",
      "  2.1887918e+00  1.7989725e-01 -2.1621011e-01  5.0124598e+00\n",
      " -3.5616598e+00  1.2086409e+00 -4.5154667e-01 -8.7126243e-01\n",
      "  1.3995730e+00  1.4029152e+00 -1.5404794e+00 -2.9209018e+00\n",
      " -2.2288544e+00  1.3557918e+00  3.3139563e+00  1.7514637e+00\n",
      " -3.9829149e+00 -1.6204801e+00 -5.2506372e-02 -1.4356444e+00\n",
      "  5.3345728e-01  3.3798435e-01 -4.1252460e+00  2.0712099e+00\n",
      "  1.2715617e+00  2.0093160e+00  4.1237950e-01 -9.9155492e-01\n",
      "  1.4769186e+00  3.7711194e+00  5.4898796e+00  4.4043598e+00\n",
      "  3.4388750e+00  1.2972058e+00  1.0330830e+00 -2.3295174e+00\n",
      "  3.8727739e+00  6.5479743e-01 -2.3007319e+00  9.3062568e-01]\n",
      "you : [-2.1102378   2.1661057   2.5413637  -2.1360884  -4.2761083   0.64214146\n",
      " -0.17338476 -3.7725706   1.8567042   6.9009647  -4.5196013   1.5100207\n",
      " -1.6658849  -3.0163598  -1.7710338  -0.1795108  -0.3876567  -1.5482688\n",
      "  1.9586277  -1.9975096  -2.2405107   2.0573096  -1.6725112  -0.9607023\n",
      " -0.49253988 -0.42847204 -0.43720222 -1.5695249  -6.1580677  -1.8636496\n",
      " -3.4673834   0.3774259  -5.5795484  -3.5314636  -3.3381548   1.229655\n",
      "  4.731356    8.962945    3.5132046  -1.8100016   2.9935725  -1.0678153\n",
      "  0.18490654  2.7064576  -0.12280294  1.2109466   0.7672894   0.18451521\n",
      "  0.54856545  1.5558867   1.5349067   0.9756927  -1.9361385  -0.72363496\n",
      "  3.8148656  -6.2873135   1.4577361   0.02956344  0.0393008   3.9561708\n",
      " -0.73195714  2.8090498   0.22283572 -1.2441041  -1.9524012   0.85368025\n",
      " -1.163397   -2.2420304  -1.5456142   0.492424   -0.22825001 -2.5852373\n",
      " -6.2825813   3.4452956   1.3593857   1.8088558   1.401423    7.0807223\n",
      "  1.0647396   4.58452    -1.6770988   1.9285312  -1.0584662  -3.3305683\n",
      "  3.8983788  -1.4054809   4.943275   -1.1854903  -3.4505935   3.6204853\n",
      " -1.8186246   1.643997    6.8617435  -0.21586657  1.4541328   0.97777057]\n",
      "help : [ 3.9393585   1.7003576  -0.3030237  -2.3076727  -2.5632756   1.233705\n",
      " -1.9719042  -0.45577693 -1.1241544  -5.5109577   0.83122706 -3.5263093\n",
      "  1.7934618  -4.303415    2.595596   -2.193612    0.03999567  1.3279395\n",
      " -4.9738536  -1.1956145  -1.3610314  -3.8844018   5.8317947   2.2901983\n",
      "  0.9775901  -2.3878262   1.1480348   1.5030792  -3.6365929   3.6006124\n",
      " -2.993801   -1.4101758  -5.411689    3.5653763   1.1165195  -1.9467181\n",
      " -0.7558024   2.8891993   2.777415   -1.1629101  -1.2969496   1.3894187\n",
      "  0.7088305   4.1369834  -4.1985807   0.8161218  -2.694728    1.3137141\n",
      " -0.77841055  1.1853025   0.9705574  -2.7786949  -1.2541966   1.1231353\n",
      "  0.5344245  -2.0673308   7.017131   -1.765007   -1.0453231   7.668632\n",
      " -0.63426435 -1.7350467   2.8291268  -4.3275375   3.875176    0.14678657\n",
      " -1.7555779   4.4914026   0.7014797   0.8635775   0.98858386 -2.6128442\n",
      " -3.503703    2.6728132  -0.7443032   4.9734592   0.04748869 -2.2956078\n",
      " -1.994663    0.74941766  4.6464543   0.5756609  -4.0801077  -2.160851\n",
      " -1.9738133   1.2981485   0.35544503 -1.9142431   0.2757563   2.7681718\n",
      "  1.524246   -3.6171424   5.9479685   2.0794377   1.6563258  -1.6234171 ]\n",
      "me : [ 2.5343139e+00 -2.2819562e-01  2.4051433e+00 -1.4253727e+00\n",
      " -3.4870636e+00 -8.7497079e-01 -1.5361110e+00 -2.1102273e+00\n",
      "  3.1665140e-01  9.2194796e+00 -1.5096232e+00  6.1812162e+00\n",
      " -5.8996325e+00 -5.9460421e+00  1.2050481e+00 -1.7537009e+00\n",
      "  3.3947716e+00  2.3069544e+00  2.0008550e+00 -1.6349943e+00\n",
      " -5.5563893e+00  1.9947534e+00  1.4579927e+00  1.6778679e+00\n",
      " -1.5128889e+00  2.9563820e-01 -2.4780061e+00 -1.6699877e+00\n",
      " -2.0907075e+00 -3.3236742e-03 -3.8753204e+00 -1.5983161e+00\n",
      " -6.4708304e+00 -3.9235711e+00 -1.2918247e+00  3.5804242e-02\n",
      "  3.9733496e+00  7.0607629e+00 -4.2800283e-01 -2.8259006e+00\n",
      "  6.5113264e-01  4.3205991e-01 -2.4602845e+00  1.4627119e+00\n",
      " -7.6882505e-01 -4.2273731e+00  2.3921289e+00  3.2349384e+00\n",
      "  1.7469642e+00 -1.7941663e+00  1.7725629e+00  4.7740960e-01\n",
      " -1.7188802e-01 -1.3896358e+00  3.1743085e+00 -2.5562878e+00\n",
      " -1.8345951e+00  1.5887566e+00 -6.4401281e-01 -1.0755658e-03\n",
      " -1.3971206e+00 -3.6744273e-01 -7.9627728e-01 -4.6992631e+00\n",
      " -4.1218045e-01  2.5464263e+00  4.3379819e-01 -2.6500750e-01\n",
      "  1.0487170e+00  1.9253941e+00 -1.7776340e-01 -3.8897600e+00\n",
      " -1.4846458e+00  1.5515264e+00  2.4892392e+00  5.0425262e+00\n",
      " -5.3702176e-01  7.9717851e+00  4.0107765e+00  2.5580397e+00\n",
      "  5.6763774e-01  2.5397527e+00 -4.3708830e+00 -3.0350575e+00\n",
      "  4.8775930e+00 -9.8740137e-01  2.2605324e+00 -1.7620872e+00\n",
      " -2.4141595e+00  2.2532015e+00 -6.2186372e-01  3.5289663e-01\n",
      "  1.7223573e+00 -4.7201961e-01  1.1684213e+00  5.5948716e-01]\n",
      "? : [ 1.803947   -1.7313943   2.2867446   5.333964   -3.7049766  -0.77636707\n",
      "  0.5046022  -2.116296   -1.9781387  -3.3876944   1.3061562   1.0176015\n",
      "  1.2272842  -0.49276122 -1.9123883   2.1656294  -1.5705848  -3.4279308\n",
      "  3.162125    1.1834764  -1.8020235   0.2631452   0.21555004  0.2717225\n",
      " -3.9318213   0.28404692 -0.69469357 -0.91216916  3.5198708  -2.5837102\n",
      " -0.04604769 -2.1392627  -3.3099947  -3.3300538  -0.11602026  1.4259056\n",
      "  2.180945   -2.4255972  -1.7902455  -1.4346828  -1.6382797  -0.58981323\n",
      " -2.3314095   2.66014     0.94362366 -0.7114136   2.468862    0.9040526\n",
      " -1.6620475   5.6875715   0.75027823 -0.8878555  -1.0057442   0.4288575\n",
      " -2.2362556  -0.25556296  1.7466214  -1.9008187   2.8253932   2.0774636\n",
      " -0.42209694 -0.3653426   4.3182716  -2.4236264  -1.768964   -2.29498\n",
      "  1.0284953   2.227358    0.7664051   2.0459127  -2.5410907   1.273746\n",
      "  3.7361836   0.3024544   1.1354828   9.211281   -0.07427698  1.8767858\n",
      " -1.4799738   2.1943896   8.622773    1.2963958  -6.375043    1.4202353\n",
      "  6.8631163  -6.0301585  -2.1635892   0.6068831  -1.2389734  -0.33301708\n",
      " -1.1161984  -2.947012    5.4976444  -2.374786   -2.898677    0.1009509 ]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') # if any FileNotFoundError , run from anconda prompt \"python -m spacy download en\"\n",
    "nlp.vocab.vectors_length\n",
    "doc = nlp('hello can you help me?')\n",
    "doc\n",
    "for token in doc:\n",
    "    print(\"{} : {}\".format(token, token.vector))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "- Direction of vectors matters\n",
    "- \"Distance\" between words = angle between the vectors\n",
    "- Cosine similarity\n",
    "    - 1: If vectors point in the same direction\n",
    "    - 0: If they are perpendicular\n",
    "    - -1: If they point in opposite directions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercise 2: Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramreddymyla\\Anaconda3\\envs\\rasax\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3167076852929806"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.similarity(nlp(\"can\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramreddymyla\\Anaconda3\\envs\\rasax\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7952184229586672"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.similarity(nlp(\"dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.similarity(nlp(\"cat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercise 3: word vectors with spaCy using ATIS dataset\n",
    "- Create a 2D array X with as many rows as there are sentences in the dataset, where each row is a vector describing that sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nlp_atis_words.txt', \"r\") as word_list:\n",
    "    sentences = word_list.read().split(',')\n",
    "with open('nlp_atis_labels.txt', \"r\") as word_list:\n",
    "    labels = word_list.read().split(',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spacy model: nlp\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Calculate the length of sentences\n",
    "n_sentences = len(sentences)\n",
    "\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "\n",
    "# Initialize the array with zeros: X\n",
    "import numpy as np\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    #X[idx, :] = doc.vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  show me the cheapest round trip fare from baltimore to dallas"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
